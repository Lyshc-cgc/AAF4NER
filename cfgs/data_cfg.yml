# Attention! ALL paths must be relative to the 'config.yml' file!

data_path: data/ontonotes/ontonotes5.py
num_proc: 6

# process config
gold_span: False  # if True, we use gold span from OntoNotes5. If False, we get span from scratch by spaCy and stanza parsers
batch_size: 4096 # batch size for data processing
split: test  # train, dev, test
shuffle: True  # whether to shuffle the data
select: 1000  # select a subset of data. If you want to use all data, set select as 0 or empty
preprocessed_dir: data/ontonotes/preprocess  # the directory to store the preprocessed data
continue: True  # whether to continue to use the data last time
continue_dir: data/ontonotes/continue  # the directory to store the continued data to be annotated

support_set: True  # whether to sample support set
k_shot: 1  # the number of examples for each label in the training set
sample_split: train  # the dataset split you want to sample support set from.
ss_cache_dir: data/ontonotes/support_set  # the directory to store the support set cache

statistics_dir: data/ontonotes/statistics  # the directory to store the statistics of the dataset
########################################################
# if gold_span is False, we get span from scratch
# set config as follows

eval_dir: data/ontonotes/eval  # evaluation results file dir
eval_quality: True  # whether to evaluate the quality of the spans recognized by stanza and spaCy parsers

# strict or loose. In strict mode, we get spans based on intersection of spaCy and Stanza results.
# In loose mode, we get spans based on union of spaCy and Stanza results.
cuda_devices: all  # specify which GPU to use, 'all' or comma-split str like '0,1,2,...,n-1' (consume that you have n GPUs)
#mode: loose  # strict or loose
span_portion: 0.4  # The proportion of the longest span length to sentence length. To filter out long span.
cand_constituent:  # the candidate constituent labels to be extracted from the constituency parsing results
  - NP  # noun phrase
  - CD  # Cardinal number
  - JJ  # Adjective
  - ADJP  # adjective phrase
  - ADVP  # adverb phrase
  - NNP  # Proper noun, singular
  - NNPS  #  Proper noun, plural
  - NML # nominal
  - QP  # Quantifier phrase
#  - NN  # Noun, singular or mass
#  - PP  # Prepositional phrase
spacy_model:
  # https://spacy.io/api/top-level#spacy.load
  # for spacy.load function, we need to specify 'name'
  name: en_core_web_trf  # for English, we can use en_core_web_sm, en_core_web_md, en_core_web_lg, en_core_web_trf
stanza_model:
  # https://stanfordnlp.github.io/stanza/pipeline.html
  lang: en  # for English
  processors: tokenize, ner, pos, constituency  # specify processors, comma-seperated
  # dir: /data1/gcchen/stanza_data  # default ~/stanza_resources

  # tokenizer init
  # https://stanfordnlp.github.io/stanza/tokenize.html#options
  tokenize_pretokenized: True
  tokenize_no_ssplit: True  # https://stanfordnlp.github.io/stanza/tokenize.html#tokenization-without-sentence-segmentation