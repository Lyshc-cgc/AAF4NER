# Attention! ALL paths must be relative to the 'config.yml' file!

cuda_devices: all  # use all available GPUs
cache_dir: data/{dataset_name}/anno_res  # cache directory
eval_dir: data/{dataset_name}/eval  # evaluation results file dir
gold_span: False  # if True, we use gold span from annotation. If False, we get span from scratch by spaCy and stanza parsers
analysis: False  # whether to add analysis process in the output
simple_des: False  # whether to use simple type description

prompt_template: >-
  {system_role}
  {task_prompt}
  {types_prompt}
  {guidelines}
  {examples_prompt}

system_role: >-
  You are a professional and helpful crowdsourcing entity annotator using English with the help of description of types.
types_prompt: True
instance_template: >-
  instruction: You are about to read a sentence. Your task is to identify all '{label}' named entities in the sentence.
  Your output should be a sentence with the entity mention marked with the "@@" and "##" symbols, where "@@" marks the 
  start of the entity and "##" marks the end of the entity.
  If there is no suitable entity mention in the sentence, you just only repeat the sentence.
  sentence: "{sentence}"
  output: {output}

examples:
  - label: PERSON
    sentence: "Some investors say there is a good chance that the trust will , instead , seek to convert the company 's shares to cash , in some sort of friendly restructuring that would n't involve just dumping stock on the market ."
    output: "Some investors say there is a good chance that the trust will , instead , seek to convert the company 's shares to cash , in some sort of friendly restructuring that would n't involve just dumping stock on the market ."

  - label: DATE
    sentence: "Rogers played hist first match on February 19 , 2004 against Jamaica , in Nain ."
    output: "Rogers played hist first match on @@ February 19 , 2004 ## against Jamaica , in Nain ."

  - label: EVENT
    sentence: "Among the most famous is the Battle of Hulao Pass , where a coalition of dissidents led by Yuan Shao clashed with Dong Zhuo 's elite armies in the novel Romance of the Three Kingdoms ."
    output: "Among the most famous is the @@ Battle of Hulao Pass ## , where a coalition of dissidents led by Yuan Shao clashed with Dong Zhuo 's elite armies in the novel Romance of the Three Kingdoms ."

  - label: CARDINAL
    sentence: "One state environmental regulator returned a report because `` it was n't heavy enough , it could n't have been correct , '' Mr. Maguire says ."
    output: "@@ One ## state environmental regulator returned a report because `` it was n't heavy enough , it could n't have been correct , '' Mr. Maguire says ."

  - label: PERSON
    sentence: "Thus , optimistic entrepreneurs await a promised land of less red tape -- just as soon as Uncle Sam gets around to arranging it ."
    output: "Thus , optimistic entrepreneurs await a promised land of less red tape -- just as soon as @@ Uncle Sam ## gets around to arranging it ."

  - label: NORP
    sentence: "American Fred Merkel won his 2nd rider 's championship and Honda won the manufacturer 's championship ."
    output: "@@ American ## Fred Merkel won his 2nd rider 's championship and Honda won the manufacturer 's championship ."

  - label: GPE
    sentence: "The Tokyo maker of ceramic capacitors said it purchased a plant in Plymouth ."
    output: "The @@ Tokyo ## maker of ceramic capacitors said it purchased a plant in @@ Plymouth ##."

  - label: LAW
    sentence: "The U.S. - Japan Security Treaty can continue , sort of ."
    output: "@@ The U.S. - Japan Security Treaty ## can continue , sort of ."

  - label: ORG
    sentence: "The LDP won by a landslide in the last election , in July 1986 ."
    output: "The @@ LDP ## won by a landslide in the last election , in July 1986 ."

  - label: PERCENT
    sentence: "A recent example is the 3 % consumption tax on all commercial activities ."
    output: "A recent example is the @@ 3 % ## consumption tax on all commercial activities ."

  - label: ORDINAL
    sentence: "On second thought , make that just mom ."
    output: "On @@ second ## thought , make that just mom ."

  - label: MONEY
    sentence: "`` But I 'm going to lose $ 50,000 to $ 60,000 on it ."
    output: "`` But I 'm going to lose @@ $ 50,000 to $ 60,000 ## on it ."

  - label: WORK_OF_ART
    sentence: "But James Madison refuted that argument in one of the most celebrated political treatises ever written , No. 10 of the Federalist Papers ."
    output: "But James Madison refuted that argument in one of the most celebrated political treatises ever written , @@ No. 10 ## of @@ the Federalist Papers ## ."

  - label: FAC
    sentence: "The station is the rebuilt Dundee Tay Bridge railway station , which had been built by the North British Railway ."
    output: "The station is the rebuilt @@ Dundee Tay Bridge railway station ## , which had been built by the North British Railway."

  - label: TIME
    sentence: "On this morning , he does n't sell much in Radzymin , either ."
    output: "On @@ this morning ## , he does n't sell much in Radzymin , either ."

  - label: LOC
    sentence: "The tribe is one of the poorest in the Pacific Northwest ."
    output: "The tribe is one of the poorest in @@ the Pacific Northwest ##."

  - label: QUANTITY
    sentence: "Daily output is expected to decline by at least another 500,000 barrels next year ."
    output: "Daily output is expected to decline by @@ at least another 500,000 barrels ## next year ."

  - label: PRODUCT
    sentence: "Coca - Cola Co. yesterday said singer Elton John signed to appear in an ad for Diet Coke ."
    output: "Coca - Cola Co. yesterday said singer Elton John signed to appear in an ad for @@ Diet Coke ##."

  - label: LANGUAGE
    sentence: "`` I got to get back to school and straighten out my English . ''"
    output: "`` I got to get back to school and straighten out my @@ English ## . ''"

  - label: EVENT
    sentence: "It does n't pay a dividend , and this trust needs income ."
    output: "It does n't pay a dividend , and this trust needs income ."



annotators: # choose annotating model from your cfgs below.
#  -
#   name: Yi  # good
#   chat: False
#   checkpoint: ckpt/01-ai/Yi-34B-Chat-8bits # https://huggingface.co/01-ai/Yi-34B-Chat-8bits
#    # https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ#prompt-template-mistral
#   anno_temperature: 0  # temperature for this model. We expect the judge model output deterministic results, so we set temperature to 0.1.
#   anno_top_p: 0.6  # top_p for this model. The smaller the value, the more deterministic the model output is.
#   anno_max_tokens: 150  # maximum number of tokens to generate per output sequence.
#   repetition_penalty: 1  # set to 1 to avoid repetition penalty
#   anno_bs: 40  # batch size for this model
#   dtype: float16  # https://docs.vllm.ai/en/latest/models/engine_args.html#cmdoption-dtype
#   gpu_memory_utilization: 0.8
#
#  -
#   name: Mistral
#   chat: False
#   checkpoint: ckpt/TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ # https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ
#    # https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ#prompt-template-mistral
#   anno_temperature: 0  # temperature for this model. We expect the judge model output deterministic results, so we set temperature to 0.1.
#   anno_top_p: 0.6  # top_p for this model. The smaller the value, the more deterministic the model output is.
#   anno_max_tokens: 150 # maximum number of tokens to generate per output sequence.
#   repetition_penalty: 1  # set to 1 to avoid repetition penalty
#   anno_bs: 40  # batch size for this model
#   dtype: float16  # https://docs.vllm.ai/en/latest/models/engine_args.html#cmdoption-dtype
#   gpu_memory_utilization: 0.8

  -
    name: st-20-wo-an
    chat: False
    checkpoint: ckpt/Qwen/Qwen1.5-32B-Chat-GPTQ-Int4  # your path to the model checkpoint
    # qwen has system prompt. We can input the examples in a form of chatting
    # https://huggingface.co/Qwen/Qwen1.5-14B-Chat#quickstart
    anno_temperature: 0  # temperature for this model. We expect the judge model output deterministic results, so we set temperature to 0.1.
    anno_top_p: 0.5  # top_p for this model. The smaller the value, the more deterministic the model output is.
    anno_max_tokens: 100  # maximum number of tokens to generate per output sequence.
    repetition_penalty: 1  # set to 1 to avoid repetition penalty
    anno_bs: 10  # batch size for this model
    dtype: auto  # https://docs.vllm.ai/en/latest/models/engine_args.html#cmdoption-dtype
    gpu_memory_utilization: 0.9
    stream: False  # if True, the model will be used in stream mode. This is useful for chat models.

#  -
#   name: AquilaChat2  # good
#   chat: False
#   checkpoint: ckpt/TheBloke/AquilaChat2-34B-GPTQ # https://huggingface.co/TheBloke/AquilaChat2-34B-GPTQ
#   anno_temperature: 0  # temperature for this model. We expect the judge model output deterministic results, so we set temperature to 0.1.
#   anno_top_p: 0.5  # top_p for this model. The smaller the value, the more deterministic the model output is.
#   anno_max_tokens: 150  # maximum number of tokens to generate per output sequence.
#   repetition_penalty: 1  # set to 1 to avoid repetition penalty
#   anno_bs: 40  # batch size for this model
#   dtype: float16  # https://docs.vllm.ai/en/latest/models/engine_args.html#cmdoption-dtype
#   gpu_memory_utilization: 0.8
