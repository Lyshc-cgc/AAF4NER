# Attention! ALL paths must be relative to the 'config.yml' file!
name: sc-1-shot-00  # the name of the configuration
cache_dir: data/{dataset_name}/anno_res  # cache directory
eval_dir: data/{dataset_name}/eval  # evaluation results file dir
gold_span: False  # if True, we use gold span from annotation. If False, we get span from scratch by spaCy and stanza parsers
support_set_dir: data/{dataset_name}/support_set  # support set directory
k_shot: 1  # set more than 0 if use few-shot setting. Else, set 0 if not use few-shot setting.
des_format: simple  # type description format , 'simple' for simple description, 'full' for full description, 'empty' for no description
subset_size: 0.5  # the number of types in the subset. you can set between 0 and 1 , or set an integer number.
repeat_num: 6  # the number of times to repeat each label.

prompt_template: >-
  {system_role}
  {task_prompt}
  {types_prompt}
  {guidelines}
  {examples_prompt}

system_role: >-
  You are a professional and helpful crowdsourcing data annotator using English with the help of description of types.

task_prompt:
  multi_qa: ~  # None
  batch_qa: >-
    Identify the entities and recognize their types in the sentence.
    The output should be a string in the format of the tuple list,  like'[(type 0, entity 0), (type 1, entity 1), ...]'.

types_prompt: True
instance_template:
  multi_qa: >-
    instruction: Given types ({subset_types}). You should identify these types of entities in the sentence.
      The output should be a string in the format of the tuple list,  like'[(type 0, entity 0), (type 1, entity 1), ...]'.
    sentence: "{sentence}"
    
    output: {output}
  batch_qa: >-
    sentence: "{sentence}"
    output: {output}