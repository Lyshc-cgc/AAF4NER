# Attention! ALL paths must be relative to the 'config.yml' file!

cuda_devices: all  # use all available GPUs
cache_dir: data/{dataset_name}/anno_res  # cache directory
eval_dir: data/{dataset_name}/eval  # evaluation results file dir
gold_span: False  # if True, we use gold span from annotation. If False, we get span from scratch by spaCy and stanza parsers
simple_des: False  # whether to use simple type description

prompt_template: >-
  {system_role}
  {task_prompt}
  {types_prompt}
  {guidelines}
  {examples_prompt}

# for chat model using chat template
prompt_template_chat: >-
  {system_role}
  Here is your task:
  ### Task
  {task_prompt}
  
  Here are types and their descriptions:
  ### Types
  {types_prompt}

system_role: >-
  You are a professional and helpful crowdsourcing data annotator using English.

task_prompt: >-
  You are about to read a sentence with an entity mention marked with square brackets (i.e, '[' and ']'), 
  where '[' refers to the start of the entity mention and ']' refers to the end of the entity mention.
  First, you need to determine if the mention is a special named entity instead of a common noun phrase.
  Then, you should annotate the given entity mention using the provided types.
  If there is no suitable type, you can choose 'O' as answer.
  The output should be a JSON string in the format of '{{"analysis": "your analysis process in a concise manner", "answer": "your answer"}}'.

types_prompt: True
instance_template: >-
  sentence: "{sentence}"
  output: {output}

examples:
  ontonotes:
    - sentence: "While Goosen was busy measuring out [ his plots ] , the Duke of Edinburgh , Prince Alfred of Edinburgh , visited the Cape Colony ."
      output: >-
        {{
          "analysis": "According to the context in the sentence, the entity mention 'his plots' is just a common noun phrase. There is no suitable type for it. So, I should annotate it as 'O'",
          "answer": "O"
          }}
    - sentence: "[ One ] state environmental regulator returned a report because `` it was n't heavy enough , it could n't have been correct , '' Mr. Maguire says ."
      output: >-
        {{
          "analysis": "According to the context in the sentence, the entity mention 'One' is a special named entity which is a cardinal number ('CARDINAL'). So, I should annotate it as 'CARDINAL'",
          "answer": "CARDINAL"
          }}
    - sentence: "Rogers played hist first match on [ February 19 , 2004 ] against Jamaica , in Nain ."
      output: >-
        {{
          "analysis": "According to the context in the sentence, the entity mention 'February 19 , 2004' is a special named entity which is a date ('Date') when Rogers played his first match. So I should annotate it as 'DATE'",
          "answer": "DATE"
          }}
    - sentence: "Thus , optimistic entrepreneurs await a promised land of less red tape -- just as soon as [ Uncle Sam ] gets around to arranging it ."
      output: >-
        {{
          "analysis": "According to the context in the sentence, the entity mention 'Uncle Sam' is a special named entity which is a person name ('PERSON'), because it can get around to arrange land of less red tape. So I should annotate it as 'PERSON'",
          "answer": "PERSON"
          }}
    - sentence: "[ American ] Fred Merkel won his 2nd rider 's championship and Honda won the manufacturer 's championship ."
      output: >-
        {{
          "analysis": "According to the context in the sentence, the entity mention 'American' is a special named entity which is an adjectival forms of adjectival forms of a nationality ('NORP'). So I should annotate it as 'NORP'",
          "answer": "NORP"
          }}
    - sentence: "The [ Tokyo ] maker of ceramic capacitors said it purchased a plant in Plymouth ."
      output: >-
        {{
          "analysis": "According to the context in the sentence, the entity mention 'Tokyo' is a special named entity which is a city ('GPE'), because the maker of ceramic capacitors is located in Tokyo. So I should annotate it as 'GPE'",
          "answer": "GPE"
          }}
    - sentence: "[ The U.S. - Japan Security Treaty ] can continue , sort of ."
      output: >-
        {{
          "analysis": "According to the context in the sentence, the entity mention 'The U.S. - Japan Security Treaty' is a special named entity which is a law ('LAW'), because it is a security treaty. So I should annotate it as 'LAW'",
          "answer": "LAW"
          }}
    - sentence: "The [ LDP ] won by a landslide in the last election , in July 1986 ."
      output: >-
        {{
          "analysis": "According to the context in the sentence, the entity mention 'LDP' is a special named entity which is an organization ('ORG'), because it is a political party. So I should annotate it as 'ORG'",
          "answer": "ORG"
          }}
    - sentence: "A recent example is the [ 3 % ] consumption tax on all commercial activities ."
      output: >-
        {{
          "analysis": "According to the context in the sentence, the entity mention '3 %' is a special named entity which is a percent ('PERCENT'), because it is a consumption tax rate. So I should annotate it as 'PERCENT'",
          "answer": "PERCENT"
          }}
    - sentence: "On [ second ] thought , make that just mom ."
      output: >-
        {{
          "analysis": "According to the context in the sentence, the entity mention 'second' is a special named entity which is an ordinal number ('ORDINAL'). So I should annotate it as 'ORDINAL'",
          "answer": "ORDINAL"
          }}
    - sentence: "`` But I 'm going to lose [ $ 50,000 to $ 60,000 ] on it ."
      output: >-
        {{
          "analysis": "According to the context in the sentence, the entity mention '$ 50,000 to $ 60,000' is a special named entity which is a money ('MONEY'), because it is a monetary value. So I should annotate it as 'MONEY'",
          "answer": "MONEY"
          }}
    - sentence: "But James Madison refuted that argument in one of the most celebrated political treatises ever written , No. 10 of [ the Federalist Papers ] ."
      output: >-
        {{
          "analysis": "According to the context in the sentence, the entity mention 'the Federalist Papers' is a special named entity which is a work of art ('WORK_OF_ART'), because it is a political treatises. So I should annotate it as 'WORK_OF_ART'",
          "answer": "WORK_OF_ART"
          }}
    - sentence: "The station is the rebuilt [ Dundee Tay Bridge ] railway station , which had been built by the North British Railway ."
      output: >-
        {{
          "analysis": "According to the context in the sentence, the entity mention 'Dundee Tay Bridge' is a special named entity which is a facility ('FAC'), because it is a railway station. So I should annotate it as 'FAC'",
          "answer": "FAC"
          }}
    - sentence: "On [ this morning ] , he does n't sell much in Radzymin , either ."
      output: >-
        {{
          "analysis": "According to the context in the sentence, the entity mention 'this morning' is a special named entity which is a time ('TIME'). So I should annotate it as 'TIME'",
          "answer": "TIME"
          }}
    - sentence: "The tribe is one of the poorest in [ the Pacific Northwest ]."
      output: >-
        {{
          "analysis": "According to the context in the sentence, the entity mention 'the Pacific Northwest' is a special named entity which is a location ('LOC'), because it is a natural region. So I should annotate it as 'LOC'",
          "answer": "LOC"
          }}
    - sentence: "Daily output is expected to decline by [ at least another 500,000 barrels ] next year ."
      output: >-
        {{
          "analysis": "According to the context in the sentence, the entity mention 'at least another 500,000 barrels' is a special named entity which is a quantity ('QUANTITY'), because it is a measurement. So I should annotate it as 'QUANTITY'",
          "answer": "QUANTITY"
          }}
    - sentence: "Coca - Cola Co. yesterday said singer Elton John signed to appear in an ad for [ Diet Coke ]."
      output: >-
        {{
          "analysis": "According to the context in the sentence, the entity mention 'Diet Coke' is a special named entity which is a product ('PRODUCT'), because it is a product name. So I should annotate it as 'PRODUCT'",
          "answer": "PRODUCT"
          }}
    - sentence: "`` I got to get back to school and straighten out my [ English ] . ''"
      output: >-
        {{
          "analysis": "According to the context in the sentence, the entity mention 'English' is a special named entity which is a language ('LANGUAGE'), because it is a named language. So I should annotate it as 'LANGUAGE'",
          "answer": "LANGUAGE"
          }}
    - sentence: "Among the most famous is the [ Battle of Hulao Pass] , where a coalition of dissidents led by Yuan Shao clashed with Dong Zhuo 's elite armies in the novel Romance of the Three Kingdoms ."
      output: >-
        {{
          "analysis": "According to the context in the sentence, the entity mention 'Battle of Hulao Pass' is a special named entity which is an event ('EVENT'), because it is clash between the dissidents led by Yuan Shao and Dong Zhuo 's elite armies. So I should annotate it as 'EVENT'",
          "answer": "EVENT"
          }}
    - sentence: "[ The Dow Jones Industrial Average ] fell 26.23 points to 2662.91 ."
      output: >-
        {{
          "analysis": "According to the context in the sentence, the entity mention 'The Dow Jones Industrial Average' is an named entity which is an index, because it is a stock market index.  However, there is no suitable type for it. So I should annotate it as 'O'",
          "answer": "O"
          }}

  conll:

annotators: # choose annotating model from your cfgs below.
#  -
#   name: Yiâ€“20  # good
#   chat: False
#   checkpoint: ckpt/01-ai/Yi-34B-Chat-8bits # https://huggingface.co/01-ai/Yi-34B-Chat-8bits
#    # https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ#prompt-template-mistral
#   anno_temperature: 0  # temperature for this model. We expect the judge model output deterministic results, so we set temperature to 0.1.
#   anno_top_p: 0.6  # top_p for this model. The smaller the value, the more deterministic the model output is.
#   anno_max_tokens: 150  # maximum number of tokens to generate per output sequence.
#   repetition_penalty: 1  # set to 1 to avoid repetition penalty
#   anno_bs: 20  # batch size for this model
#   dtype: float16  # https://docs.vllm.ai/en/latest/models/engine_args.html#cmdoption-dtype
#   gpu_memory_utilization: 0.9

  -
    name: '20'
    chat: False
    # https://huggingface.co/Qwen/Qwen1.5-32B-Chat
    checkpoint: ckpt/Qwen/Qwen1.5-32B-Chat-GPTQ-Int4 # your path to the model checkpoint
    # qwen has system prompt. We can input the examples in a form of chatting
    # https://huggingface.co/Qwen/Qwen1.5-14B-Chat#quickstart
    anno_temperature: 0.05  # temperature for this model. We expect the judge model output deterministic results, so we set temperature to 0.1.
    anno_top_p: 0.5  # top_p for this model. The smaller the value, the more deterministic the model output is.
    anno_max_tokens: 150  # maximum number of tokens to generate per output sequence.
    repetition_penalty: 1  # set to 1 to avoid repetition penalty
    anno_bs: 10  # batch size for this model
    dtype: auto  # https://docs.vllm.ai/en/latest/models/engine_args.html#cmdoption-dtype
    gpu_memory_utilization: 0.9
    stream: False  # if True, the model will be used in stream mode. This is useful for chat models.

#  -
#   name: Mistral
#   chat: False
#   checkpoint: ckpt/TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ # https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ
#    # https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ#prompt-template-mistral
#   anno_temperature: 0  # temperature for this model. We expect the judge model output deterministic results, so we set temperature to 0.1.
#   anno_top_p: 0.6  # top_p for this model. The smaller the value, the more deterministic the model output is.
#   anno_max_tokens: 100 # maximum number of tokens to generate per output sequence.
#   repetition_penalty: 1  # set to 1 to avoid repetition penalty
#   anno_bs: 40  # batch size for this model
#   dtype: float16  # https://docs.vllm.ai/en/latest/models/engine_args.html#cmdoption-dtype
#   gpu_memory_utilization: 0.8

#  -
#   name: AquilaChat2  # good
#   chat: False
#   checkpoint: ckpt/TheBloke/AquilaChat2-34B-GPTQ # https://huggingface.co/TheBloke/AquilaChat2-34B-GPTQ
#   anno_temperature: 0  # temperature for this model. We expect the judge model output deterministic results, so we set temperature to 0.1.
#   anno_top_p: 0.5  # top_p for this model. The smaller the value, the more deterministic the model output is.
#   anno_max_tokens: 100  # maximum number of tokens to generate per output sequence.
#   repetition_penalty: 1  # set to 1 to avoid repetition penalty
#   anno_bs: 40  # batch size for this model
#   dtype: float16  # https://docs.vllm.ai/en/latest/models/engine_args.html#cmdoption-dtype
#   gpu_memory_utilization: 0.8
